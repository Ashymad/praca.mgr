\PassOptionsToPackage{binary-units}{siunitx}
\PassOptionsToPackage{table}{xcolor}
\documentclass[pl,12pt]{aghdpl}
% \documentclass[en,11pt]{aghdpl}  % praca w języku angielskim

% Lista wszystkich języków stanowiących języki pozycji bibliograficznych użytych w pracy.
% (Zgodnie z zasadami tworzenia bibliografii każda pozycja powinna zostać utworzona zgodnie z zasadami języka, w którym dana publikacja została napisana.)
\usepackage[english,polish]{babel}

% Użyj polskiego łamania wyrazów (zamiast domyślnego angielskiego).
\usepackage{polski}

\usepackage[utf8]{inputenc}

% Załączniki

\usepackage[toc, page]{appendix}
\renewcommand\appendixpagename{Załączniki}
\renewcommand\appendixtocname{Załączniki}

% dodatkowe pakiety

\usepackage{mathtools}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{rotating}
\usepackage{amsthm}
\usepackage{float}% do umieszczenia floatów [H]
\usepackage{enumitem}
\setlist{nosep} % or \setlist{noitemsep} to leave space around whole list
\usepackage[bookmarks,hidelinks]{hyperref}

\usepackage{import}
\usepackage{bm}
\usepackage{pgfplots}
\pgfplotsset{compat=1.16}
\usepackage{tikzscale}
\usepgfplotslibrary{external}
\tikzexternalize

\usetikzlibrary{positioning}
\usetikzlibrary{fit}
\tikzset{%
  highlight/.style={rectangle,rounded corners,fill=red!15,draw,fill opacity=0.5,thick,inner sep=0pt}
}
\newcommand{\tikzmark}[2]{\tikz[overlay,remember picture,baseline=(#1.base)] \node (#1) {#2};}
%
\newcommand{\Highlight}[1][submatrix]{%
    \tikz[overlay,remember picture]{
    \node[highlight,fit=(left.north west) (right.south east)] (#1) {};}
}

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
% Środowisko float do kodu źródłowego \begin{program}

\floatstyle{plaintop}
\ifcsname{chapter}\endcsname%
    \newfloat{program}{!tbh}{lop}[chapter]
\else%
    \newfloat{program}{!tbh}{lop}
\fi
\floatname{program}{Kod źr.}

% Kod poniżej powoduje, że floaty nie wylatują poza granice sekcji

\usepackage{placeins}

\ifcsname{chapter}\endcsname%
    \let\Oldchapter\chapter%
    \renewcommand{\chapter}{\FloatBarrier\Oldchapter}
\fi

\let\Oldsection\section%
\renewcommand{\section}{\FloatBarrier\Oldsection}

\let\Oldsubsection\subsection%
\renewcommand{\subsection}{\FloatBarrier\Oldsubsection}

\let\Oldsubsubsection\subsubsection%
\renewcommand{\subsubsection}{\FloatBarrier\Oldsubsubsection}

% --- < bibliografia > ---


\usepackage[
style=numeric,
sorting=none,
%
% Zastosuj styl wpisu bibliograficznego właściwy językowi publikacji.
language=autobib,
autolang=other,
% Zapisuj datę dostępu do strony WWW w formacie RRRR-MM-DD.
urldate=iso,
seconds=true,
% Nie dodawaj numerów stron, na których występuje cytowanie.
backref=false,
% Podawaj ISBN.
isbn=true,
% Nie podawaj URL-i, o ile nie jest to konieczne.
url=false,
%
% Ustawienia związane z polskimi normami dla bibliografii.
maxbibnames=3,
% Jeżeli używamy Bibera:
backend=biber
]{biblatex}

\usepackage{csquotes}
% Ponieważ `csquotes` nie posiada polskiego stylu, można skorzystać z mocno zbliżonego stylu chorwackiego.
\DeclareQuoteAlias{croatian}{polish}

\addbibresource{bibliografia.bib}

% Przecinki zamiast kropek do oddzielenia pól wpisu bibliograficznego
% i dwukropek po nazwisku autora, bez kropki na końcu
\AtBeginBibliography{
    \renewcommand\labelnamepunct{:\space}
    \renewcommand\newunitpunct{\addcomma\space}
    \renewcommand{\finentrypunct}{}
    \renewcommand{\bibopenparen}{\addcomma\addspace}
    \renewcommand{\bibcloseparen}{\addspace}
}

% Nie wyświetlaj wybranych pól.
%\AtEveryBibitem{\clearfield{note}}


% ------------------------
% --- < listingi > ---

% Użyj czcionki kroju Times.
\usepackage{newtxtext}
\usepackage{newtxmath}

\usepackage{listings}
\usepackage{jlcode}
\lstset{language=Julia}

\lstset{%
        literate={ą}{{\k{a}}}1
           {ć}{{\'c}}1
           {ę}{{\k{e}}}1
           {ó}{{\'o}}1
           {ń}{{\'n}}1
           {ł}{{\l{}}}1
           {ś}{{\'s}}1
           {ź}{{\'z}}1
           {ż}{{\.z}}1
           {Ą}{{\k{A}}}1
           {Ć}{{\'C}}1
           {Ę}{{\k{E}}}1
           {Ó}{{\'O}}1
           {Ń}{{\'N}}1
           {Ł}{{\L{}}}1
           {Ś}{{\'S}}1
           {Ź}{{\'Z}}1
           {Ż}{{\.Z}}1
}

% Ustawienia pakietu lstlisting do umieszczania kodu

\usepackage{color}

\definecolor{mygreen}{rgb}{0,0.6,0}
\definecolor{mygray}{rgb}{0.5,0.5,0.5}
\definecolor{mymauve}{rgb}{0.58,0,0.82}

\lstset{%
  backgroundcolor=\color{white},     % choose the background color
  basicstyle=\ttfamily\footnotesize, % size of fonts used for the code
  breaklines, breakatwhitespace,     % automatic line breaking only at whitespace
  commentstyle=\color{mygreen},      % comment style
  numbers=left,
  showstringspaces=false,
  numberstyle=\tiny,
  frame=l,
  escapeinside={*@}{@*},           % if you want to add LaTeX within your code
  keywordstyle=\color{blue},         % keyword style
  stringstyle=\color{mymauve}        % string literal style
}

% ------------------------

\AtBeginDocument{%
        \renewcommand{\tablename}{Tab.}
        \renewcommand{\figurename}{Rys.}
}

% ------------------------
% --- < tabele > ---

\usepackage{array}
\usepackage{tabularx}
\usepackage{multirow}
\usepackage{booktabs}
\usepackage{makecell}
\usepackage[flushleft]{threeparttable}

% defines the X column to use m (\parbox[c]) instead of p (`parbox[t]`)
\newcolumntype{C}[1]{>{\hsize=#1\hsize\centering\arraybackslash}X}


%---------------------------------------------------------------------------

\author{Szymon Piotr Mikulicz}

\makeatletter% Poniższe makra są wyłącznie zdefiniowane w klasie aghdpl-imir
\@ifclassloaded{aghdpl}{%

  \sex{m} % Mężczyzna - m; kobieta - cokolwiek
  \shortauthor{S.\ Mikulicz}
  \albumnum{279253}
  \address{Legionów 49, 05-220 Zielonka}

  \titlePL{Wykorzystanie uczenia maszynowego do identyfikacji metody kompresji
  sygnału akustycznego}
  \titleEN{{The use of machine learning to identify the method of acoustic
  signal compression}}

  \shorttitlePL{Identyfikacja kompresji audio} % skrócona wersja tytułu
  \shorttitleEN{Identification of audio compression}

  % rodzaj pracy bez końcówki fleksyjnej np. inżyniersk, magistersk
  \thesistypePL{magistersk}
  \thesistypeEN{master's}

  \supervisor{dr hab. inż. Bartłomiej Borkowski}

  \reviewer{prof. dr hab. inż. Jerzy Wiciak}

  \degreeprogrammePL{Inżynieria Akustyczna}
  \degreeprogrammeEN{Acoustic Engineering}

  \specialisationPL{Drgania i Hałas w Technice i Środowisku}
  \specialisationEN{Vibration and Noise in Technology and Environment}

  \graduationyear{2019}
  \years{2018/2019}
  \yearofstudy{II}
  \formPL{stacjonarne}
  \formEN{full-time}

  % zgoda na publikację pracy w internecie: t-zgoda, cokolwiek 
  % innego-brak zgody
  \agree{t}

  % praktyka (dyplomowa)
  \apprenticeship{Katedra Mechaniki i Wibroakustyki}

  \department{Department of Mechanics and Vibroacoustics}

  \facultyPL{Wydział Inżynierii Mechanicznej i Robotyki}
  \facultyEN{Faculty of Mechanical Engineering and Robotics}

  \thesisplan{% Przykładowy plan pracy, należy omówić z promotorem
    \begin{enumerate}
    \item Omówienie tematu pracy i sposobu realizacji z promotorem.
    \item Zebranie i opracowanie literatury dotyczącej tematu pracy.
    \item Zebranie i opracowanie wyników badań.
    \item Analiza wyników badań, ich omówienie i zatwierdzenie przez promotora.
    \item Opracowanie redakcyjne.
    \end{enumerate}
  }

  \summaryPL{\indent\indent%
	  {[Treść streszczenia]}
  }
  \summaryEN{\indent\indent%
	  {[Summary text]}
  }

  \acknowledgements{%
    Dziękuję mojemu promotorowi, prof.~Borkowskiemu, za cierpliwość, Stevenowi
    G.  Johnsonowi za MDCT.jl, Donaldowi E. Knuthowi za \TeX\ oraz moim
    przyjaciołom ot tak, bo mogę.
  }

  \setlength{\cftsecnumwidth}{10mm}
}{}%
\makeatother%

\date{\today}

%---------------------------------------------------------------------------
\setcounter{secnumdepth}{4}
\brokenpenalty=10000\relax

\begin{document}

\titlepages

% Ponowne zdefiniowanie stylu `plain`, aby usunąć numer strony z pierwszej strony spisu treści i poszczególnych rozdziałów.
\fancypagestyle{plain}
{%
        % Usuń nagłówek i stopkę
        \fancyhf{}
        % Usuń linie.
        \renewcommand{\headrulewidth}{0pt}
        \renewcommand{\footrulewidth}{0pt}
}

\setcounter{tocdepth}{2}
{\singlespacing\tableofcontents}
\clearpage

\chapter{Wprowadzenie}
\section{Cel pracy}
Serwisy internetowe sprzedające muzykę w postaci bezstratnych plików audio
wymagają od sprzedawców plików w takim formacie \cite{BCWhyLossless}, lecz nie
przeprowadzają weryfikacji bezstratności tych plików poprzez sprawdzenie czy
plik nie był uzyskany poprzez dekompresję z pliku w formacie stratnym
\cite{ZhouWangJinYan2015}. Pliki uzyskane w ten sposób mogą się charakteryzować
słyszalnie gorszą jakością, w zależności od rodzaju i stopnia zastosowanej
kompresji, a ponadto ponowna kompresja stratna, stosowana przez serwisy do
przygotowania plików w innych formatach, w znaczącym stopniu pogarsza ich jakość
\cite{YangShiHuang2010}.

W pracy przedstawiono wykorzystanie metod uczenia maszynowego do rozpoznania
czy sygnał cyfrowy audio został uprzednio poddany kompresji stratnej oraz jaki
rodzaj i stopień kompresji został zastosowany. Ponadto zaimplementowano
alternatywne rozwiązanie, korzystające z algorytmu opartego o wykrywanie
pozostałości po, stosowanych w kompresji stratnej, transformatach okienkowanych.

\section{Zawartość pracy}
Drugi rozdział opisuje zagadnienia związane z kompresją plików dźwiękowych, w
tym kompresję bezstratną i stratną, ze szczególnym skupieniem uwagi na tej
drugiej. Zawarto w nim także szczegóły dotyczące działania pięciu
popularnych kodeków, wybranych do analizy w pracy.

Trzeci rozdział przedstawia szczegóły implementacji algorytmu, wraz z podjętymi
krokami usprawnień i opisem uzyskanej biblioteki programistycznej. Także
zawarta jest architektura modelu, wraz z opisem zawartych w nim elementów oraz
szczegółami implementacyjnymi.

Czwarty rozdział zawiera wyniki ewaluacji zarówno algorytmu, jak i modelu w
różnych konfiguracjach. Opisana jest zgromadzona baza danych ewaluacyjnych oraz
procedura zastosowana w procesie ewaluacji.

Ostatni rozdział składa się z wniosków podsumowujących dokonania pracy i
wyników uzyskanych podczas ewaluacji oraz propozycji dalszych kierunków badań.

\chapter{Kompresja audio}
\section{Wprowadzenie}
W informatyce pojęcie kompresji odnosi się do procesu zmniejszenia rozmiaru
pliku. Jako że pliki multimedialne posiadają duży rozmiar bez użycia kompresji
w porównaniu do innego typu plików wykorzystywanych przez użytkowników
komputera (\SI{10}{\second} nieskompresowanego pliku audio, w formacie płyty
CD, zajmuje około \SI{1.7}{\mebi\byte}, dla porównania cały tekst powieści
\textit{Potop} Henryka Sienkiewicza \cite{Sienkiewicz2010}, w postaci
nieskompresowanego ciągu znaków zakodowanych UTF-8, zajmuje około
\SI{0.9}{\mebi\byte}), a ponadto przesyłane są często przez łącze sieciowe do
odbiorcy, zmniejszenie ich rozmiaru oszczędza ogromne ilości miejsca na dysku
jak i przepustowości sieci (kompresja bezstratna pozwala skompresować pliki
audio do \num{50}-\SI{70}{\percent} oryginalnego rozmiaru, a stratna nawet
poniżej \SI{1}{\percent} oryginalnego rozmiaru bez utraty odczuwalnej jakości
\cite{Beurden2015, kamedo22014}). Z tego powodu kompresja audio, video i
obrazów jest stosowana powszechnie, nieskompresowane pliki multimedialne
używane są wyłącznie, gdy wymagany jest szybki dostęp do ich fragmentów i brak
obaw o pogorszenie jakości, na przykład podczas procesu ich edycji.

Kompresja bezstranta, wykorzystująca metody powszechnie stosowane także do
kompresji innych plików (np. ZIP, gzip), nie osiąga dużej skuteczności na
plikach multimedialnych, z powodu wysokiej entropii tego rodzaju plików
\cite{Sayood2002}. Wobec tego stosuje się metody pozwalające na dalsze
zmniejszenie rozmiaru, kosztem utraty możliwości odtworzenie oryginalnego
sygnału po dekompresji, z tego powodu ten typ kompresji nazywa się kompresją
stratną.

\section{Kompresja bezstratna}

W procesie kompresji stratnej uzyskuje się zmniejszenie rozmiaru pliku bez
utraty informacji. Uzyskuje się to poprzez zastosowanie pewnych przekształceń
które zostaną tu wytłumaczone na przykładzie kompresji FLAC
(eng. \textit{Free Lossless Audio Codec}), z dwóch powodów: FLAC jest obecnie
najpopularniejszym formatem kompresji bezstratnej oraz posiada w pełni otwartą
specyfikację i referencyjny enkoder.

\begin{figure}[!tbh]
  \centering
  \import{./vecgraphics/}{FLAC-scheme.pdf_tex}
  \caption{Schemat kompresji bezstratnej (na przykładzie FLAC)}
  \label{fig:FLAC_scheme}
\end{figure}

Podczas procesu kompresji FLAC występują cztery główne kroki (patrz rys.
\ref{fig:FLAC_scheme}): fragmentacja, dekorelacja, modelowanie i kodowanie.
Pierwszy krok, czyli fragmentacja dzieli sygnał cyfrowy na fragmenty (eng.
\textit{blocks}), których długość wybierana jest na tyle krótka by model
stworzony w trzecim kroku był jak najbardziej efektywny i na tyle długa by
nadmiarowość (eng. \textit{overhead}) wynikająca z konieczności zapisu
parametrów zastosowanych do kompresji fragmentu była jak najmniejsza. 

W drugim kroku przeprowadzana jest dekorelacja kanałów w pliku audio, w
przypadku pliku stereofonicznego kanały prawy $r$ i lewy $l$ zamieniane są na środkowy
$m = \frac{l + r}{2}$ i boczny $s = l - r$. Pozwala to znacznie zwiększyć
poziom kompresji w dalszych krokach, ponieważ typowo duża korelacja pomiędzy
kanałami powoduje że kanał różnicowy (boczny) zawiera niewielkie wartości
amplitudy próbek.

Trzeci krok jest najbardziej istotny gdyż w nim tworzony jest model
matematyczny w taki sposób, by różnica pomiędzy sygnałem wygenerowanym przez
niego a sygnałem rzeczywistym (nazywana błędem lub residuum), wymagała
jak najmniejszej liczby bitów na próbkę (eng. \textit{bits-per-sample}).
Standard FLAC przewiduje dwa typy modeli: wielomian lub kodowanie predykcyjne
LPC (eng. \textit{Linear Predictive Coding}). Dopasowanie wielomianu wymaga
mniejszej mocy obliczeniowej lecz wynik jest mniej dokładny niż LPC.

Ostatni krok to kodowanie entropijne uzyskanego w poprzednim kroku sygnału
błędu. W kompresji FLAC wykorzystane jest kodowanie Huffmana, które
wykorzystuje nierównomierności rozkładu częstotliwości występowania sekwencji
bitów w danych, zapisując najczęściej występujące sekwencję mniejszą liczbą
bitów. Zazwyczaj związane jest to z zapisem tzw.\ słownika, który
przyporządkowuje sekwencje bitów do kodów Huffmana. Natomiast, ponieważ dane
błędu uzyskane w tym procesie posiadają rozkład Laplace'a (podwójnie
wykładniczy), możliwe jest zastosowanie szczególnego układu kodów Huffmana,
nazwanych kodami Rice'a. Własnością tych kodów jest możliwość ich wygenerowania
na podstawie pojedynczego parametru opisującego rozkład danych (parametru
Rice'a), ponadto standard FLAC pozwala na podzielenie fragmentu na części,
gdzie każda część posiada inny parametr Rice'a, co pozwala na lepsze
dopasowanie go do zmienności rozkładu w trakcie trwania sygnału.

Poprawnie działający enkoder i dekoder pozwolą otrzymać, po kompresji i
dekompresji pliku, plik w którym próbki sygnału audio będą takie same jak w
pliku oryginalnym. Z tego powodu wykrycie czy plik został poddany takiemu
procesowi niemożliwe na podstawie samego sygnału audio.


procesowi niemożliwe na podstawie samego sygnału audio.

\section{Kompresja stratna}

Celem kompresji stratnej, w przeciwieństwie do bezstratnej nie jest stworzenie
mniejszego pliku który po dekompresji odtworzy sygnał wejściowy co do próbki, lecz
stworzenie pliku dużo mniejszego, który po dekompresji i odtworzeniu będzie
możliwie nierozróżnialny od oryginalnego dla większości słuchaczy. Dlatego też
ten typ kompresji jest dużo bardziej skomplikowany gdyż wykorzystuje nie tylko
te techniki co kompresja bezstratna, ale również wymaga zastosowania wiedzy
z dziedziny psychoakustyki. W związku z tym przetestowanie działania kodeku
wymaga testów odsłuchowych co znacząco spowalnia proces tworzenia nowych
rozwiązań.

\begin{figure}[!tbh]
  \centering
  \import{./vecgraphics/}{PAC-scheme.pdf_tex}
  \caption{Schemat kompresji stratnej}
  \label{fig:PAC_scheme}
\end{figure}

Na rysunku \ref{fig:PAC_scheme} przedstawiony jest uproszczony schemat typowego
enkodera PAC (eng. \textit{Perceptual Audio Coding}) wykorzystywanego w
kompresji stratnej. Posiada on cztery główne elementy: transformację
analizującą, kwantyzator, enkoder i model psychoakustyczny.

Pierwszym elementem jest transformacja analizująca, która zamienia sygnał audio
na postać którą może wykorzystać kwantyzator wraz z modelem psychakustycznym.
Każdy z opisanych w tym rozdziale kodeków wykorzystuje w tym celu miedzy innymi
zmodyfikowaną transformację kosinusową MDCT (eng. \textit{Modified Discrete
Cosine Transform}) określoną wzorem:
\begin{equation}
  X_k = \sum_{n=0}^{2N-1}x_n\cos\left[\frac{\pi}{N}
  \left(n+\frac{1}{2}+\frac{N}{2}\right)\left(k+\frac{1}{2}\right)\right].
\end{equation}
Jest to funkcja liniowa $F\colon \bm{R}^{2N} \to \bm{R}^N$, która przekształca
$2N$ liczb rzeczywistych $x_0, \dotsc, x_{2N+1}$ w $N$ liczb rzeczywistych
$x_0, \dotsc, x_{N+1}$. Posiada ona szczególną właściwość wykorzystywaną w
procesie kompresji, mianowicie większość współczynników z niej uzyskanych
posiada wartości bliskie zeru.

Aby przeprowadzić transformację na sygnale, wybierana jest długość okna $l =
2c$, gdzie $c \in \bm N$, oraz skok $h \in \bm N$. Długość okna określa długość
fragmentu sygnału $\bm s$ który zostanie pomnożony przez okno $\bm w$, a
następnie poddany transformacji, natomiast skok określa co ile próbek jest
wycinany kolejny fragment. Wynikiem całej operacji jest jest macierz $\bm X =
\begin{bmatrix}\bm x_1 & \bm x_2 & \cdots  & \bm x_k\end{bmatrix}$, stworzona z
wektorów \[\bm x_n = \text{MDCT}\left\{\bm
w\begin{bmatrix}s_{(n-1)h}\\\vdots\\s_{(n-1)h+l}\end{bmatrix}\right\},\] gdzie
okno $\bm w$ jest wektorem o długości $l$, wyznaczonym na podstawie pewnej
funkcji $w(n)$, której zadaniem jest zniwelowanie efektów brzegowych. Aby
transformacja była odwracalna, okno musi być symetryczne, tzn.\ spełniać
warunek symetryczności (\ref{eq:symm_cond}) i warunek Princena-Bradleya
(\ref{eq:p-b_cond}).
\begin{equation}\label{eq:symm_cond}
  w_n = w_{l-1-n}
\end{equation}
\begin{equation}\label{eq:p-b_cond}
  w_n^2+w_{n+\frac{l}{2}}^2 = 1
\end{equation}

Sygnał audio jest także przetwarzany przez model psychakustyczny którego
zadaniem jest przewidywanie zachowania ucha ludzkiego, w taki sposób by
określić czego potencjalny słuchacz może nie usłyszeć, a co usłyszy.
Wykorzystuje on w tym celu wiedzę o konstrukcji ucha oraz wiedzę uzyskaną
poprzez przeprowadzanie testów odsłuchowych.

Informacje uzyskane z modelu psychoakustycznego są następnie stosowanie przez
kwantyzator do kwantyzacji (ograniczenia zbioru wartości) wyniku transformacji
analizującej. Elementy które model uzna za niesłyszalne dla potencjalnego
odbiorcy zostaną silniej skwantyzowane niż te które zostaną uznane za
słyszalne. Jest to proces nieodwracalny z którego wynika ,,stratność'' tego
rodzaju kompresji, w jego wyniku dostaje się także macierz wag przez którą
trzeba pomnożyć uzyskane wartości w procesie odwrotnym.

W ostatnim kroku, podobnie jak w przypadku kompresji bezstratnej, dane uzyskane
z poprzedniego kroku są zakodowane przy użyciu kodowania entropijnego. Jest ono
bardzo skuteczne na uzyskanych danych dzięki opisanej wcześniej własności
transformaty MDCT oraz procesowi kwantyzacji, które powodują wyzerowanie się
dużej liczby współczynników uzyskanych w procesie transformacji.

\begin{figure}[!tbh]
  \centering
  \import{./vecgraphics/}{IPAC-scheme.pdf_tex}
  \caption{Schemat dekompresji stratnej}
  \label{fig:IPAC_scheme}
\end{figure}

Aby z pliku skompresowanego uzyskać sygnał audio stosuje się dekompresją (patrz
rys. \ref{fig:IPAC_scheme}), gdzie kolejno następuje: dekodowanie zakodowanych
entropijnie danych, odwrotna kwantyzacja która polega na wymnożeniu danych
przez odpowiednie wagi (ten proces jednakże nie odtwarza w pełni danych z przed
kwantyzacji lecz dane zbliżone) oraz synteza, czyli zastosowanie odwrotnych
transformat analizujących, w przypadku MDCT będzie to IMDCT (eng.
\textit{Inverse Modified Discrete Cosine Transform})

\subsection{MP3}
Format MP3 (eng. \textit{MPEG-1 Layer 3}) został zdefiniowany w roku 1991 jako część
standardu MPEG-1 (eng. \textit{Moving Picture Experts Group Phase 1}) a
następnie rozszerzony w standardach MPEG-2 oraz MPEG-2.5. Do czasu uzyskania
popularności przez AAC był to najpopularniejszy kodek. Ponadto cieszył się on
dużo popularnością jako format wykorzystywany w przenośnych urządzeniach,
zwanych, na jego cześć, ,,empetrójkami'', do odsłuchiwania muzyki z powodu dużego
wsparcia sprzętowego.

W tym kodeku przed MDCT do analizy sygnału jest zastosowany również bank
filtrów PQMF (eng. \textit{Pseudo Quadrature Mirror Filter}), jest to bank filtrów
który rezygnuje z możliwości idealnej rekonstrukcji sygnału na rzecz prostszego
procesu konstrukcji względem banku filtrów QMF. Filtry banku anulują aliasing w
sąsiadujących pasmach, ponadto bank jest ortogonalny, więc filtry syntezy są
filtrami analizy odwróconymi w czasie.
%\begin{enumerate}
%  \item Projekt prototypowego filtra dolnoprzepustowego $h(n)$ o długości $M =
%    LN$, gdzie $L, M, N \in \bm Z$
%  \item Filtr musi anulować aliasing w sąsiadujących podpasmach: \[
%      \begin{array}{rl}
%        |H(e^{i\omega})|^2 + H(e^{i\frac{\pi}{N}-\omega})|^2 = 2, &
%        \quad0<|\omega|<\frac{\pi}{2N} \\
%        |H(e^{i\omega})|^2 = 0, & \quad|\omega| > \frac{\pi}{N}
%      \end{array}\]
%  \item Filtry analizy $h_k(n)$ to modulacje kosinusowe filtra $h(n)$:\[
%      h_k(n) = h(n)\cos\left[\left(k+\frac{1}{2}\right)
%      \left(n-\frac{M-1}{2}\right)\frac{\pi}{N}+\phi_k\right],\]
%      gdzie $k = 0,\dotsc,N-1$, a faza spełnia warunek:\[
%      \phi_{k+1}-\phi_k = (2r+1)\frac{\pi}{2}.\]
%  \item Bank filtrów jest ortogonalny, więc filtry syntezy są filtrami analizy
%    odwróconymi w czasie:\[
%      f_k(n) = h_k(M-1-n)\]
%\end{enumerate}
W formatach od MPEG-1 Layer I do MPEG-1 Layer III, ten bank filtrów użyto z $N = 32$
pasmami i o $M = 512$ współczynnikach, przy czym w MP3 dodatkowo do wyjścia każdego z
pasm zaaplikowano filtr Princena-Bradleya {\color{red}odnośnik}.

\begin{figure}[!tbh]
  \centering
  \includegraphics[width=0.5\textwidth]{plots/win_MP3.pgf}
  \caption{Okno sinusowe/kosinusowe}
  \label{fig:win_MP3}
\end{figure}

MDCT w tym formacie wykorzystuje okno sinusowe (nazywane też kosinusowym) (rys.
\ref{fig:win_MP3}) o długości $N$, o następującym wzorze:
\begin{equation}\label{eq:sine_win}
  w(n) = \sin\left(\frac{\pi n}{N}\right) = \cos\left(\frac{\pi n}{N} - \frac{\pi}{2}\right).
\end{equation}
MP3 wykorzystuje dwie długości okna, tzw.\ okno krótkie o długości 384 próbek i okno
długie o długości 1152 próbek.

\subsection{AAC}
Format AAC (eng. \textit{Advanced Audio Coding}) został zdefiniowany w roku 1994
jako część standardu MPEG-2 (eng. \textit{Moving Picture Experts Group Phase
1}), a następnie rozszerzony w standardzie MPEG-4. Został on stworzony jako
zastępca MP3, gdyż uznano że można uzyskać znacznie lepsze parametry kompresji
poświęcając wsteczną kompatybilność.

Główne usprawnienia względem MP3 to: ulepszone kodowanie stereo, zwiększone
możliwości doboru tablic kodowania Huffmana i zastosowanie techniki TNS (eng.
\textit{Temporal Noise Shaping}), która polega na kształtowaniu szumu w
dziedzinie czasu zamiast po zastosowanej transformacie, co pozwala uniknąć
artefaktów typu \textit{pre-echo} pojawiających się w przypadku występowania
dźwięków impulsowych. Ponadto w AAC zrezygnowano z hybrydowego banku PQMF+MDCT,
na cześć samego MDCT.

Kodek ten jest obecnie stosowany przez duże serwisy internetowe dostarczające
treści multimedialne takie jak YouTube i Netflix do kompresji ścieżek
dźwiękowych w filmach.

MDCT w tym formacie wykorzystuje miedzy innymi okno KBD (eng.
\textit{Keiser-Bessel-derived}), jest to okno pochodne okna Keisera, stworzone
by spełniało warunki zastosowania w MDCT (\ref{eq:symm_cond},
\ref{eq:p-b_cond}). Okno Kaisera ma wzór:
\begin{equation}\label{eq:kaiser_win}
  w_k(n) = \frac{I_0\left[\pi\alpha\sqrt{1-\left(\frac{2n}{N}-1\right)^2}\right]}
  {I_0(\pi\alpha)},\quad 0 \leq n \leq N,
\end{equation}
gdzie długość okna wynosi $N+1$, $I_0$ to zerowego rzędu zmodyfikowana funkcja
Bessela pierwszego rodzaju, a $\alpha$ to parametr wpływający na kształt tego
okna. Na jego podstawie zdefiniowane jest okno Kaisera-Bessela o długości $2N$
o wzorze:
\begin{equation}\label{eq:kbd_win}
  w(n) = \begin{cases}
    \sqrt{\frac{\sum_{i=0}^{n}w_k(i)}{\sum_{i=0}{N}w_k(i)}} & \text{dla }0 \leq n \leq N \\
    \sqrt{\frac{\sum_{i=0}^{2N-1-n}w_k(i)}{\sum_{i=0}{N}w_k(i)}} & \text{dla }N \leq n \leq 2N-1 \\
    0 & \text{w innym przypadku}
  \end{cases}.
\end{equation}
AAC wykorzystuje okno sinusowe (rys. \ref{fig:win_MP3}) lub KBD z parametrem
$\alpha = 4$ (rys.  \ref{fig:win_AAC}) o długości 2048 próbek, lub okno KBD z
parametrem $\alpha = 6$ o długości 256 próbek.

\begin{figure}[!tbh]
  \centering
  \includegraphics[width=0.5\textwidth]{plots/win_AAC.pgf}
  \caption{Okno KBD, $\alpha = 4$}
  \label{fig:win_AAC}
\end{figure}

\subsection{Ogg Vorbis}

Praca nad kodekiem Vorbis została rozpoczęta w roku 1993 przez Chrisa
Montgomery'iego, a obecnie jego rozwój jest nadzorowany przez organizację
Xiph.Org, której jest założycielem. Celem jest stworzenie kodeka nieobciążonego
przez licencjonowanie i prawa patentowe oraz który posiada lepsze parametry niż
inne stosowane kodeki. Format kontenera stworzony i stosowany przez tę
organizację do jej formatów nazywa się \textit{Ogg}, stąd rozszerzenie pliku
tego kontenera to \lstinline|.ogg|, a pełna nazwa pliku kontenera Ogg z audio w
formacie Vorbis to Ogg Vorbis.

Specyfikacja kodeka jest w pełni otwarta, a referencyjne implementacje dekodera
i enkodera są udostępnione na licencji typu Open Source, co pozwala każdemu na
użycie go w dowolnym celu bez ponoszenia żadnych opłat.

Kodek korzysta z transformacji MDCT, a wynikowy sygnał w dziedzinie
częstotliwości dzielony jest na szum i komponenty szczątkowe, po czym jest
poddany kwantyzacji i kwantyzacji wektorowej.

Vorbis jest obecnie używany przez najpopularniejszy serwis z muzyką
strumieniową: Spotify oraz jest w użyciu przez studia gier komputerowych.

MDCT w tym formacie wykorzystuje okno zboczowe (eng. \textit{slope}) (rys.
\ref{fig:win_OGG}) o długości $N = 2^{p}$, gdzie $p \in [6,13] \land p \in \bm N$, o wzorze:
\begin{equation}\label{eq:slope_win}
  w(n) = \sin\left(\frac{\pi}{2}\sin^2\left(\frac{\left(n +
  \frac{1}{2}\right)}{N\pi}\right)\right).
\end{equation}
Wykorzystanie zmiennej długości okna o więcej niż dwóch długościach jak w AAC,
MP3 i AC-3, pozwala Vorbis adaptować lepiej kompresję do charakteru
czasowo-częstotliwościowego sygnału.

\begin{figure}[!tbh]
  \centering
  \includegraphics[width=0.5\textwidth]{plots/win_OGG.pgf}
  \caption{Okno zboczowe}
  \label{fig:win_OGG}
\end{figure}

\subsection{AC-3}
AC-3 (nazywany też Dolby Digitial, DD, ATSC A/52) to format kompresji stworzony
przez firmę Dolby Laboratories na potrzeby kin, wspierający wielokanałową konfigurację
kanałów 5.1. AC-3 miało zastąpić dotychczasowe rozwiązania analogowego zapisu
sygnału audio jako cyfrowy format zapisu ścieżki audio na taśmie filmowej.
Pierwszy film który został wypuszczony ze ścieżką dźwiękową w tym formacie to
\textit{Batman Returns} w roku 1992.

Kodek jest obecnie ciągle w użyciu w kinie, choć zastępowany przez Dolby
Sorround 7.1 i Dolby Atmos, ponadto jest wykorzystywany do kodowania ścieżek
dźwiękowych w filmach dystrybuowanych na płytach DVD i Blu-ray.

MDCT w tym formacie wykorzystuje okno KBD (\ref{eq:kaiser_win},
\ref{eq:kbd_win}), z parametrem $\alpha = 5$ (rys. \ref{fig:win_AC3}) o
długości 512 lub 256 próbek.
\begin{figure}[!tbh]
  \centering
  \includegraphics[width=0.5\textwidth]{plots/win_AC3.pgf}
  \caption{Okno KBD, $\alpha = 5$}
  \label{fig:win_AC3}
\end{figure}

\subsection{WMA}

WMA (eng. \textit{Windows Media Audio}) to kodek stworzony w roku 1999 przez
firmę Microsoft w celu, podobnie jak AAC i Vorbis, stworzenia kodeka o lepszych
parametrach niż MP3. Termin WMA może się też odnosić do nowszych kodeków: WMA
Lossless --- kodeka bezstratnego, WMA Voice --- kodeka dostosowanego do
kompresji głosu lub WMA Pro --- nowszej, usprawnionej wersji kodeka. W tej
pracy WMA oznaczać będzie format podstawowy WMA.

WMA jest standardowym enkoderem wykorzystywanym przez oprogramowanie Windows
Media Player systemu Microsoft Windows do zapisu sygnału audio. Odtwarzanie
plików jest wspierane przez wszystkie komputery z tym systemem i wiele urządzeń
przenośnych.

MDCT w tym formacie wykorzystuje nieznane okno o długości $N = 2^p$, gdzie $p
\in [8,12] \land p \in\bm N$. Okno posiada zmienną długość podobnie jak w
przypadku Ogg Vorbis.

\chapter{Realizacja}
Aby stworzyć proces pozwalający na wykrycie formatu z którego sygnał audio
został dekodowany, przeanalizowano dwa podejścia, nie tylko wykorzystano
techniki uczenia maszynowego, ale ponadto, zaimplementowano algorytm który, w
przeciwieństwie do modelu, nie wymaga uprzedniego treningu.
\section{Podejście algorytmiczne}
Implementowany algorytm oparty został o algorytm opisany w
{\color{red}odnośnik}. Algorytm ten potrafi wskazać czy dany sygnał został
skompresowany przez pewien kodek audio, którego parametry: transformacja
analizująca $T(x)$, długość okna $N \in \bm N_+$, funkcja okna $w(n)$ oraz skok
$h \in \left[1, N\right]$ są znane.
Przedstawia się on następująco:
\begin{enumerate}
  \item Wycięcie $\frac{N}{2}+1$ fragmentów o długości $L = nN$, gdzie $n \in
    \bm N$, z sygnału $\bm s$,
    poczynając od indeksu $i$ do indeksu $i+\frac{N}{2}$
    \begin{equation}
      \begin{bmatrix}
        s_i \\\vdots\\ s_{i+L-1}
      \end{bmatrix},
      \begin{bmatrix}
        s_{i+1} \\\vdots\\ s_{i+L}
      \end{bmatrix}, \dotsc,
      \begin{bmatrix}
        s_{i+\frac{N}{2}} \\\vdots\\ s_{i+\frac{N}{2}+L-1}
      \end{bmatrix}
    \end{equation}
  \item Wykonanie krótkoczasowej transformacji $T(x)$ z oknem $w(n)$ o długości
    $N$ i skoku $h$ na fragmentach uzyskanych w poprzednim kroku uzyskując
    $\frac{N}{2}+1$ macierzy $\hat{\bm S}_i$
    \begin{equation}
      \hat{\bm S}_i = \underset{w(n), N, h}{T}\left(
        \begin{bmatrix}
          s_i \\\vdots\\ s_{i+L-1}
        \end{bmatrix}\right)
    \end{equation}
  \item Policzenie średniej modułów logarytmów dziesiętnych modułów macierzy
    $\hat{\bm S}_i$ uzyskując $\frac{N}{2}+1$ średnich $\left<\hat{\bm S}_i\right>$
    \begin{equation}
      \left<\hat{\bm S}_i\right> =
      \frac{1}{L}\sum_m\sum_n\left|\log_{10}
      \left(\left|\hat{S}_{i, mn}\right|\right)\right|
    \end{equation}
  \item Wyznaczenie modułów różnic pomiędzy kolejnymi średnimi uzyskując
    wektor $\bm d_i$ o długości $\frac{N}{2}$
    \begin{equation}
      \bm d_i = \begin{bmatrix}
        \left|\left<\hat{\bm S}_i\right> -
        \left<\hat{\bm S}_{i+1}\right>\right|\\
        \left|\left<\hat{\bm S}_{i+1}\right> -
        \left<\hat{\bm S}_{i+2}\right>\right|\\
        \vdots\\
        \left|\left<\hat{\bm S}_{i+\frac{N}{2}-1}\right> -
        \left<\hat{\bm S}_{i+\frac{N}{2}}\right>\right|
      \end{bmatrix}
    \end{equation}
    \item Znalezienie wartości maksymalnej $d_{i,\max}$ wektora $\bm d_i$ oraz
      indeksu $k_{i,\max}$ który posiada ta wartość w tym wektorze
      \begin{equation}
        d_{i,\max} = \max_k\left\{d_{i, k}\right\}
      \end{equation}
      \begin{equation}
        k_{i,\max} = \argmax_k\left\{d_{i,k}\right\} \iff d_{i,\max} =
        d_{i,k_{i,\max}}
      \end{equation}
    \item Powtarzanie poprzednich kroków $M$ razy, zwiększając wartość $i$ o $L$
      w każdym kroku, tak że w $m$-tym kroku $i = i_0 + (m-1)L$, gdzie $i_0$ to
      dowolny wybrany indeks sygnału $\bm s$. Wynikiem operacji są wektory
      wartości maksymalnych $\bm d_{\max}$ i odpowiadających im indeksów $\bm
      k_{\max}$ o długości $M$
      \begin{equation}
        \bm d_{\max} = \begin{bmatrix}
          d_{i_0,\max}\\
          d_{i_0+L,\max}\\
          \vdots\\
          d_{i_0+(M-1)L,\max}
        \end{bmatrix},
        \bm k_{\max} = \begin{bmatrix}
          k_{i_0,\max}\\
          k_{i_0+L,\max}\\
          \vdots\\
          k_{i_0+(M-1)L,\max}
        \end{bmatrix}
      \end{equation}
    \item Znalezienie okresu $p_{\min}$, zdefiniowanego jako największa wartość
      $p \in [3, h]$ dla której współczynnik zmienności $V_{r}(p)$ reszt $r(p,
      j)$ z dzielenia elementów wektora indeksów wartości maksymalnych $\bm
      k_{\max}$ przez $p$ osiąga wartość minimalną
      \begin{equation}
        r(p, j) = k_{\max, j}\mod p
      \end{equation}
      \begin{equation}
        \overline r(p) = \frac{1}{M}\sum_{j=1}^{M}r(p, j)
      \end{equation}
      \begin{equation}
        V_{r}(p) = \frac{1}{\overline r(p)}\sqrt{\frac{1}{M}
        \sum_{j=1}^{M}\left(r(p, j) - \overline r(p)\right)^2}
      \end{equation}
      \begin{equation}
        p_{\min} = \max\left\{\argmin_{3 \leq p \leq h}
        \left\{V_{r}(p)\right\}\right\}
      \end{equation}
    \item Wyznaczenie wektora kątów $\bm\phi_k$ poprzez pomnożenie stosunku
      reszty z dzielenia elementów wektora $\bm k_{\max}$ przez
      okres $p_{\min}$ do $p_{\min}$ przez $2\pi$
      \begin{equation}
        \bm\phi_k = \frac{2\pi}{p_{\min}}\begin{bmatrix}
          k_{\max,1}\mod p_{\min}\\
          \vdots\\
          k_{\max,M}\mod p_{\min}\\
        \end{bmatrix}
      \end{equation}
    \item Obliczenie jednoliczbowego wskaźnika $C_{T(x),w(n),N,h}$ którego
      wielkość jest wprost proporcjonalna do prawdopodobieństwa zastosowania
      kompresji o parametrach $T(x)$, $w(n)$, $N$ i $h$. Jest
      on zdefiniowany jako odległość od środka układu średniej geometrycznej
      punktów określonych w układzie współrzędnych radialnych jako pary
      $(d_{\max, j}, \phi_{k, j})$, gdzie promieniami są elementy wektora
      wartości maksymalnych $\bm d_{\max}$, natomiast kątami są odpowiadające im
      elementy wektora kątów $\bm\phi_k$
      \begin{equation}
        C_{T(x),w(n),N,h} =\frac{1}{M}\sqrt{\left(\sum_{j=1}^{M}d_{\max,j}\sin
        \phi_{k,j}\right)^2+\left(\sum_{j=1}^{M}d_{\max,j}\cos
        \phi_{k,j}\right)^2}
      \end{equation}
\end{enumerate}

Algorytm ten usprawnia poprzednie rozwiązania poprzez dodanie siódmego kroku
który automatycznie znajduje wartość $p_{\min}$ oraz modyfikuje krok trzecie
poprzez wprowadzenie średniej modułów logarytmów modułów zamiast modułu
logarytmów średniej kwadratowej, pozwalając na znacznie efektywniejszą
implementację.
\subsection{Biblioteka \textit{IOLA.jl}}
Procedury algorytmu zaimplementowano w języku programowania \textit{Julia} w
postaci biblioteki o nazwie \textit{IOLA} (eng.\ \textit{Identification Of
Lossy Audio}). Udostępnia ona dwa elementy: moduł \lstinline|Codec| i funkcję
\lstinline|analyze(signal, transform, segment_length, overlap, normalize)|.
Ponadto w module \lstinline|Codec.Utils| udostępnione są funkcje
\lstinline|findperiod(indexes, domain)| oraz
\lstinline|radiusofmean(radiuses, angles)|.

Moduł \lstinline|Codec| zawiera parametry kodeków, które następnie można
wykorzystać do analizy fragmentu audio. Udostępnione są w tym celu: funkcja
\lstinline|Codec.getparams(codec_type)|, funkcja
\lstinline|Codec.gettransform(codec_params)|, oraz enumerator
\lstinline|Codec.CodecType| zawierający obsługiwane kodeki, obecnie są to:
\lstinline|Codec.MP3|, \lstinline|Codec.AAC|, \lstinline|Codec.AC3|,
\lstinline|Codec.OGG| i \lstinline|Codec.WMA|. Aby uzyskać parametry kodeka
należy wywołać funkcję \lstinline|Codec.getparams()| na którejś wartości
enumeratora \lstinline|Codec.CodecType|, uzyskując strukturę
\lstinline|Codec.CodecParams| która zawiera pola \lstinline|transform|,
\lstinline|window|, \lstinline|length| i \lstinline|hop|, które odpowiadają
parametrom $T(x)$, $w(n)$, $N$ i $h$. Wywołanie funkcji
\lstinline|gettransform()| na uzyskanej strukturze natomiast pozwala uzyskać
krótkoczasową transformatę $\underset{w(n),N,h}{T(x)}$.

Funkcja \lstinline|analyze()| jest najważniejszą częścią biblioteki, wykonuje
ona kroki algorytmu od pierwszego do szóstego zwracając macierz $M \times 2$,
która w pierwszej kolumnie zawiera elementy wektora $\bm d_{\max}$ natomiast w
drugiej kolumnie elementy wektora $\bm k_{\max}$:
\[\begin{bmatrix}
    d_{\max,1} & k_{\max,1}\\
    \vdots & \vdots\\
    d_{\max,M} & k_{\max,M}
\end{bmatrix}.\]
Wymaga ona podania fragmentu sygnału $\bm s$ na którym chce się przeprowadzić
analizę, krótkoczasowej transformaty $\underset{w(n),N,h}{T(x)}$, długości
fragmentu $L$ oraz skoku $h$. Ponadto posiada ona opcjonalny parametr który,
jeśli ustalony na wartość \lstinline|true|, dodaje dodatkowy krok po kroku
czwartym, polegający na normalizacji wektora $\bm d_i$, czyli odjęciu średniej
$\overline{d_i}$ i podzieleniu przez odchylenie standardowe $s_{d_i}$ każdego
elementu, zastępując go wektorem znormalizowanym $\bm d_{i, \text{norm}}$ w
dalszych krokach.
\begin{equation}
  \overline{d_i} = \frac{1}{M}\sum_{j=1}^{M}d_{i,j}
\end{equation}
\begin{equation}
  s_{d_i} = \sqrt{\frac{1}{M-1}\sum_{j=1}^{M}\left(d_{i, j} -
  \overline{d_{i}}\right)},
\end{equation}
\begin{equation}
  \bm d_{i, \text{norm}} = \frac{1}{s_{d_i}}\begin{bmatrix}
    d_{i,1} - \overline{d_i}\\
    \vdots\\
    d_{i,M} - \overline{d_i}
  \end{bmatrix}
\end{equation}
Ten dodatkowy krok pozwala łatwiej porównać wyniki uzyskane dla różnych
sygnałów, lecz zmniejsza różnice pomiędzy wynikami dla różnych stopni kompresji
utrudniając tym samym ich rozróżnienie.

Funkcje pomocnicze \lstinline|findperiod()| i \lstinline|radiusofmean()|
wykonują odpowiednio siódmy i dziewiąty krok algorytmu. Pierwsza zwraca
$p_{\min}$ po podaniu jej wektora $\bm k_{\max}$ i zakresu szukania np.
$[3,h]$, natomiast druga pozwala wyliczyć $C_{T(x),w(n),N,h}$ na podstawie $\bm
d_{\max}$ i $\bm\phi_k$.

Kolejne użycie funkcji z tej biblioteki pozwala przeprowadzić analizę pliku pod
kątem konkretnego kodeka, przykład takiego użycia dla formatu MP3 przedstawia
kod źródłowy \ref{lst:IOLA_example}.

\begin{program}
  \caption{Zastosowanie biblioteki \textit{IOLA.jl} do analizy kompresji MP3}
  \label{lst:IOLA_example}
  \begin{lstlisting}
  # Zaimportowanie potrzebnych bibliotek
  using IOLA
  using IOLA.Utils
  using WAV
  # Wczytanie parametrów kodeka i danych audio oraz ustalenie długości segmentu
  params = Codec.getparams(Codec.MP3)
  transform = Codec.gettransform(params)
  L = 10*params.length
  (s, fs, nbits, opt) = wavread("audio.wav")
  # Analiza sygnału
  dk = analyze(y, transform, L, params.hop)
  d = dk[:,1]
  k = dk[:,2]
  # Wyznaczenie wskaźnika *@$\color{mygreen}C_{T(x),w(n),N,h}$@*
  pmin = findperiod(k, 3:params.hop)
  phi = 2pi*mod.(k, pmin)./pmin
  C = radiusofmean(d, phi)
  \end{lstlisting}
\end{program}

Kluczowe w implementacji było wykorzystanie jak najefektywniejszych procedur, w
szczególności dla MDCT i średniej modułów logarytmów modułów, których
implementacje opisano w kolejnych punktach, w celu skrócenia
długiego czasu przetwarzania. Ponadto wykorzystano wbudowane w język
\textit{Julia} możliwości wielowątkowości, które pozwalają na rozłożenie kroków
od pierwszego do piątego na wiele rdzeni procesora jako że są one od siebie
niezależne.
\subsection{Średnia modułów logarytmów modułów}
Mając macierz $\bm X$ o wymiarach $M \times N$ średnia modułów logarytmów modułów
(od teraz nazywana po prostu ,,średnią'') jest to suma wartości absolutnych z
logarytmu o podstawie $q$ z wartości absolutnych wszystkich elementów tej
macierzy.
\begin{equation}
  \left<X\right> =
  \frac{1}{MN}\sum_{m=1}^{M}\sum_{n=1}^{N}\left|\log_{q}\left(\left|X_{mn}\right|\right)\right|
\end{equation}
Aby uprościć zagadnienie pominięto nieistotne z punktu widzenia złożoności
mnożenie przez stałą $\frac{1}{MN}$ oraz przestawiono problem na przykładzie
wektora $\bm x$ o długości $K=MN$, którego elementy $x_k = \left|X_{mn}\right|$
są modułami elementów macierzy $\bm X$  w dowolnej kolejności
\begin{equation}\label{eq:naive_algorithm}
  \left<x\right> = \sum_{k=1}^{K}\left|\log_{q}\left(x_{k}\right)\right|.
\end{equation}
Korzystając z własności modułu i własności logarytmu:
\begin{equation}
  |a| + |b| = \begin{cases}
    |a + b|, & (a \geq 0 \land b \geq 0) \lor (a < 0 \land b < 0)\\
    |a - b|, & (a > 0 \land b < 0) \lor (a < 0 \land b > 0)\\
  \end{cases},
\end{equation}
\begin{equation}
  \log_q(a) + \log_q(b) = \log_q(ab),
\end{equation}
\begin{equation}
  \log_q(a) - \log_q(b) = \log_q\left(\frac{a}{b}\right),
\end{equation}
\begin{equation}
  \log_q(a) \geq 0 \iff a \geq 1 \land \log_q(a) \leq 0 \iff a \leq 1 .
\end{equation}
Można wywnioskować:
\begin{equation}
  |\log_q(a)| + |\log_q(b)| = \begin{cases}
    |\log_q(ab)|, & (a \geq 1 \land b \geq 1) \lor (a < 1 \land b < 1)\\
    |\log_q\left(\frac{a}{b}\right)|, & (a > 1 \land b < 1) \lor (a < 1 \land b > 1)\\
  \end{cases}.
\end{equation}
Z czego, określiwszy operator $\odot$ jako
\begin{equation}\label{eq:odot_operation}
  a \odot b = \begin{cases}
    ab, & (a \geq 1 \land b \geq 1) \lor (a < 1 \land b < 1)\\
    \frac{a}{b}, & (a > 1 \land b < 1) \lor (a < 1 \land b > 1)\\
  \end{cases},
\end{equation}
wyprowadzono następujący algorytm:
\begin{equation}
  \left<x\right> = |\log_q(\overline{x_K})|, \quad\text{gdzie}\quad
  \begin{cases}
    \overline{x_1} &= x_1\\
    \overline{x_{k+1}} &= \overline{x_k}\odot x_{k+1}
  \end{cases},
\end{equation}

Jak widać w wersji ,,naiwnej'' (\ref{eq:naive_algorithm}) aby policzyć
$\left<x\right>$ należy wykonać aż $K$ operacji logarytmowania, która jest
kosztowna pod względem obliczeniowym. W usprawnionej wersji algorytmu wystarczy
jedna operacja logarytmowania bez względu na rozmiar wektora wejściowego.
Natomiast ta prosta wersja algorytmu jest bezużyteczna dla dużych wartości $K$
z powodu ograniczonej precyzji zmiennych zmiennoprzecinkowych. Im większa
wartość $K$ tym większa szansa na wykorzystanie dostępnej precyzji co objawia
się uzyskaniem z operacji $a \odot b$ wartości $0$ lub $\pm\infty$, dla
$a \neq 0 \land b \neq 0$. Wobec tego opracowano algorytm:
\begin{enumerate}
  \item Mając wektor początkowy $\bm x$ o długość $N$, należy wyznaczyć wektor
    pośredni $\bm y$ o długości
    $\left\lceil\frac{N}{2}\right\rceil$, którego elementy są wynikami
    zastosowania operacji $\odot$ (\ref{eq:odot_operation}) na kolejnych parach
    elementów wektora $\bm x$, tak że \begin{equation}
      y_i = \begin{cases}
        x_{2i-1}\odot x_{2i}, & 2i \leq N\\
        x_{2i-1}, & 2i > N
      \end{cases}
    \end{equation}
  \item Należy powtarzać krok pierwszy zastępując wektor początkowy wektorem
    wynikowym, do czasu aż wektor wynikowy będzie miał długość 1, lub skończy
    się precyzja zmiennych, po czym na uzyskanym w ten sposób wektorze
    zastosować ,,naiwny'' algorytm (\ref{eq:naive_algorithm}).
\end{enumerate}

Ta metodyka, w zależności od rozmiaru wektora i danych w nim zawartych
zmniejsza ilość operacji logarytmowania potrzebnych do wyliczenia
$\left<x\right>$. Na rysunku \ref{fig:sum_abs_log_abs} przedstawiony jest
stosunek czasu wykonywania algorytmu ,,naiwnego'' do tego algorytmu. Można
zauważyć że jest on najefektywniejszy dla rozmiarów wektora pomiędzy
10\textsuperscript{4}, a 10\textsuperscript{5} elementów, gdzie wykonuję tę samą
operację w czasie cztery razy krótszym niż algorytm ,,naiwny'', lecz nawet dla
rozmiarów wektora powyżej 10\textsuperscript{6} oferuje on czas wykonywania co
najmniej \num{2.5} raza krótszy.
\begin{figure}[!tbh]
  \centering
  \includegraphics[width=0.6\textwidth]{plots/sum_abs_log10_abs.pgf}
  \caption{Wydajność algorytmu}
  \label{fig:sum_abs_log_abs}
\end{figure}

\section{Uczenie maszynowe}
Zagadnienie rozróżniania sygnałów audio przedstawiono w postaci zagadnienia
które jest jednym z podstawowych zagadnień na których skupia się uczenie
maszynowe, mianowicie chodzi o zagadnienie rozpoznawania obrazów. Sygnał audio
można przedstawić w postaci spektrogramu, który pozwala nie tylko rozdzielić
sygnał na pasma częstotliwościowe, dzięki czemu na obrazie znajdują się
informacje czasowo-częstotliwościowe sygnału.
\subsection{Konwolucyjne Sieci Neuronowe}
Konwolucyjne sieci neuronowe (eng. \textit{CNN -- Convolutional Neural
Networks}) typowo posiadają trzy typy warstw: warstwy konwolucyjne,
warstwy podpróbkujące oraz warstwy w pełni połączone. Są one stosowane do
rozpoznawania obrazów, gdyż ich konstrukcja skutecznie wyselekcjonowuje istotne
informacje z obrazów podobnie jak oczy ludzkie.

Warstwy konwolucyjne wykonują operację splotu wejściowych tensorów z jądrem
(nazywanym też filtrem) --- tensorem dwuwymiarowym o elementach (tak zwanych
wagach) które są optymalizowane w procesie nauki sieci. Mając tensor wejściowy
o wymiarach $W \times H \times D$, odpowiadających szerokości, wysokości i
głębokości (liczbie kanałów) obrazu wejściowego, oraz kolekcje jąder $M \times
N$ o wymiarach $D \times T \times M \times N$, wpierw wykonywany jest tzw.
\textit{padding} --- proces w którym tensor wejściowy zwiększany jest o pewną
liczbę $P$ zer na krawędziach dwóch pierwszych wymiarów uzyskując tensor
wymiarach $W+2P \times H+2P \times D$. Następnie każdy z kanałów obrazu
wejściowego o wymiarach $W+2P \times H+2P$ jest splatany z każdym kolejnym
jądrem dla danego kanału od 1 do $T$ uzyskując w efekcie $D\times T$ tensorów
wynikowych splotu. Te tensory są następnie sumowane po wymiarze $D$ uzyskując
$T$ tensorów wynikowych.

W procesie pojedynczego splotu wyliczane są iloczyny wewnętrzne Frobeniusa
(sumy iloczynów elementów o tych samych indeksach) macierzy
jądra przez wycinek kanału obrazu o wymiarach jądra, poczynając od lewej górnej
krawędzi i przesuwając się w prawo o skok $S$ do prawej krawędzi po czym zaczynając
z powrotem od lewej przesunąwszy się w dół o $S$. Proces ten przedstawia się
następująco na przykładzie obrazu $\bm O$ o wymiarach $4 \times 4 \times 1$ i
jadra $\bm J$ o wymiarach $3 \times 3$, padzie $P = 0$ i skoku $S = 1$, gdzie
zaznaczono elementy macierzy biorące udział w działaniu:

\begin{equation}
  \bm O = \begin{bmatrix}
    3 & 3 & 2 & 1\\
    0 & 0 & 1 & 3\\
    3 & 1 & 2 & 2\\
    2 & 0 & 0 & 2
  \end{bmatrix},\quad
  \bm J = \begin{bmatrix}
    0 & 1 & 2\\
    2 & 2 & 0\\
    0 & 1 & 2
  \end{bmatrix},
\end{equation}
\tikzset{external/export=false}
\begin{equation}
  \begin{array}{*2{c}}
    \langle\left[\begin{array}{*4{c}}
        \tikzmark{left}{3} & 3 & 2 & 1\\
        0 & 0 & 1 & 3\\
        3 & 1 & \tikzmark{right}{2} & 2\\
        2 & 0 & 0 & 2
    \end{array}\right], J\rangle_F =
    \Highlight
    \left[\begin{array}{*2{c}}
        \tikzmark{left}{12}\tikzmark{right}{12} & \phantom{12}\\
        \phantom{10} & \phantom{17}
    \end{array}\right]
    \Highlight&
    \langle\left[\begin{array}{*4{c}}
        3 & \tikzmark{left}{3} & 2 & 1\\
        0 & 0 & 1 & 3\\
        3 & 1 & 2 & \tikzmark{right}{2}\\
        2 & 0 & 0 & 2
    \end{array}\right],\bm J\rangle_F =
    \Highlight
    \left[\begin{array}{*2{c}}
        12 & \tikzmark{left}{12}\tikzmark{right}{12}\\
        \phantom{10} & \phantom{17}
    \end{array}\right]
    \Highlight\\
    \langle\left[\begin{array}{*4{c}}
        3 & 3 & 2 & 1\\
        \tikzmark{left}{0} & 0 & 1 & 3\\
        3 & 1 & 2 & 2\\
        2 & 0 & \tikzmark{right}{0} & 2
    \end{array}\right],\bm J\rangle_F =
    \Highlight
    \left[\begin{array}{*2{c}}
        12 & 12\\
        \tikzmark{left}{10}\tikzmark{right}{10} & \phantom{17}
    \end{array}\right]
    \Highlight&
    \langle\left[\begin{array}{*4{c}}
        3 & 3 & 2 & 1\\
        0 & \tikzmark{left}{0} & 1 & 3\\
        3 & 1 & 2 & 2\\
        2 & 0 & 0 & \tikzmark{right}{2}
    \end{array}\right],\bm J\rangle_F =
    \Highlight
    \left[\begin{array}{*2{c}}
        12 & 12\\
        10 & \tikzmark{left}{17}\tikzmark{right}{17}
    \end{array}\right]
    \Highlight\\
  \end{array}.
\end{equation}
\tikzset{external/export=true}
Wynikiem tej operacji jest macierz $\bm C$ o wymiarach $2\times 2$:
\begin{equation}
  \bm C = \begin{bmatrix}
    12 & 12\\
    10 & 17
  \end{bmatrix}.
\end{equation}

Kolejnym krokiem po konwolucji jest podpróbkowanie które zmniejsza rozmiar
tensora kilkukrotnie zachowując najistotniejsze informacje. Tzw okno --- analog
jądra w konwolucji o pewnym wymiarze przesuwa się ze skokiem $S$ wybierając z
zaznaczonej części macierzy wartość maksymalną, w przypadku algorytmu
\textit{Max Pooling}, lub średnią, w przypadku algorytmu \textit{Average
Pooling}. Dla każdego kanału obrazu ten proces jest wykonywany niezależnie.
Przykład działania \textit{Max Pooling} na macierzy $\bm O$ z oknem $2 \times
2$ i skokiem $S = 2$ przedstawia się następująco:
\tikzset{external/export=false}
\begin{equation}
  \begin{array}{*2{c}}
    \max\left\{\left[\begin{array}{*4{c}}
      \tikzmark{left}{3} & 3 & 2 & 1\\
      0 & \tikzmark{right}{0} & 1 & 3\\
      3 & 1 & 2 & 2\\
      2 & 0 & 0 & 2
    \end{array}\right]\right\} =
    \Highlight
    \left[\begin{array}{*2{c}}
        \tikzmark{left}{3}\tikzmark{right}{3} & \phantom{3}\\
        \phantom{3} & \phantom{2}
    \end{array}\right]
    \Highlight&
    \max\left\{\left[\begin{array}{*4{c}}
      3 & 3 & \tikzmark{left}{2} & 1\\
      0 & 0 & 1 & \tikzmark{right}{3}\\
      3 & 1 & 2 & 2\\
      2 & 0 & 0 & 2
\end{array}\right]\right\} =
    \Highlight
    \left[\begin{array}{*2{c}}
        3 & \tikzmark{left}{3}\tikzmark{right}{3}\\
        \phantom{3} & \phantom{2}
    \end{array}\right]
    \Highlight\\
    \max\left\{\left[\begin{array}{*4{c}}
      3 & 3 & 2 & 1\\
      0 & 0 & 1 & 3\\
      \tikzmark{left}{3} & 1 & 2 & 2\\
      2 & \tikzmark{right}{0} & 0 & 2
\end{array}\right]\right\}=
    \Highlight
    \left[\begin{array}{*2{c}}
        3 & 3\\
        \tikzmark{left}{3}\tikzmark{right}{3} & \phantom{2}
    \end{array}\right]
    \Highlight&
    \max\left\{\left[\begin{array}{*4{c}}
      3 & 3 & 2 & 1\\
      0 & 0 & 1 & 3\\
      3 & 1 & \tikzmark{left}{2} & 2\\
      2 & 0 & 0 & \tikzmark{right}{2}
\end{array}\right]\right\} =
    \Highlight
    \left[\begin{array}{*2{c}}
      3 & 3\\
      3 & \tikzmark{left}{2}\tikzmark{right}{2}
    \end{array}\right]
    \Highlight\\
  \end{array}.
\end{equation}
\tikzset{external/export=true}
W wyniku uzyskana jest macierz $\bm M$ o wymiarach $2\times 2$:
\begin{equation}
  \bm M = \begin{bmatrix}
    3 & 3\\
    3 & 2
  \end{bmatrix}
\end{equation}
Trzecim typem warst stosowanych w sieciach CNN są warstwy w pełni połączone
(eng. \textit{FC -- Fully Connected}). Tego typu warstwy umieszcza się na
końcu łańcucha przetwarzania, ich zadaniem jest rozpoznanie kategorii obrazu na
podstawie cech wyseparowanych przez poprzednie warstwy konwolucyjne i
podpróbkujące. 
\begin{figure}[!tbh]
  \centering
  \begin{tikzpicture}[x=1.5cm, y=1.5cm, >=stealth]
    \tikzset{%
      every neuron/.style={
        circle,
        draw,
        minimum size=1cm
      },
      neuron missing/.style={
        draw=none, 
        scale=3,
        text height=0.333cm,
        execute at begin node=\color{black}$\vdots$
      },
      neuron missing2/.style={
        draw=none, 
        scale=3,
        text height=0.222cm,
        execute at begin node=\color{black}$\cdots$
      },
      neuron none/.style={
        draw=none
      }
    }
    \foreach \m/\l [count=\y] in {1,2,3,missing,4}{
      \node [every neuron/.try, neuron \m/.try] (input-\m) at (0,2.5-\y) {};
    }
    \foreach \m [count=\y] in {1,2,missing,3}{
      \node [every neuron/.try, neuron \m/.try ] (hidden-\m) at (1.5,2-\y) {};
    }
    \foreach \m [count=\y] in {missing2,missing2,none,missing2}{
      \node [every neuron/.try, neuron \m/.try ] (dottes-\m) at (2.55,2-\y) {};
    }
    \foreach \m [count=\y] in {1,2,missing,3}{
      \node [every neuron/.try, neuron \m/.try ] (hidden2-\m) at (3.5,2-\y) {};
    }
    \foreach \m [count=\y] in {1,missing,2}{
      \node [every neuron/.try, neuron \m/.try ] (output-\m) at (5,1.5-\y) {};
    }
    \foreach \l [count=\i] in {1,2,3,n_0}{
      \draw [<-] (input-\i) -- ++(-1,0);
      \node [] at (input-\i) {$i_{\l}$};
    }
    \foreach \l [count=\i] in {1,2,n_1}{
      \node [] at (hidden-\i) {$h_{\l}^{(1)}$};
    }
    \foreach \l [count=\i] in {1,2,n_m}{
      \node [] at (hidden2-\i) {$h_{\l}^{(m)}$};
    }
    \foreach \l [count=\i] in {1,n_{m+1}}{
      \draw [->] (output-\i) -- ++(1,0);
      \node [] at (output-\i) {$o_{\l}$};
    }
    \foreach \i in {1,...,4}{
      \foreach \j in {1,...,3}{
        \draw [->] (input-\i) -- (hidden-\j);
      }
    }
    \foreach \i in {1,...,3}{
      \foreach \j in {1,...,2}{
        \draw [->] (hidden2-\i) -- (output-\j);
      }
    }
    \foreach \l [count=\x from 0] in {Dane\\wejściowe,Warstwy\\ukryte,Warstwa\\wyjściowa}{
      \node [align=center, above] at (\x*2.5,2) {\l};
    }
  \end{tikzpicture}
  \caption{Schemat sieci w pełni połączonej}
  \label{fig:fully_connected}
\end{figure}
Schematycznie warstwy w pełni połączone przedstawia rysunek
\ref{fig:fully_connected}, sieć na nim posiada $m$ warstw ukrytych oraz warstwę
wyjściową. Aby uzyskać element wektora pierwszej warstwy ukrytej $\bm h^{(1)}$,
należy wymnożyć każdy z elementów wektora danych wyjściowych $\bm i$ przez
odpowiadający mu element wektora wag $\bm w_{0}$, zsumować wyniki mnożenia i
na wyniku wykonać funkcję nieliniową $\sigma_0$, zwaną funkcją aktywacji,
\begin{equation}
  h_k^{(1)} = \sigma_0\left(\sum_{j=1}^{n_0}i_jw_{0,k,j}\right).
\end{equation}
Analogicznie wartości kolejnych warstw ukrytych wynoszą:
\begin{equation}
  h_k^{(p)} = \sigma_{p-1}\left(\sum_{j=1}^{n_{p-1}}h_j^{(p-1)}w_{p-1,k,j}\right).
\end{equation}

W zagadnieniach rozpoznawania obrazów jako funkcję aktywacji $\sigma$ zazwyczaj
stosuje się funkcję reLU (eng. \textit{Rectified Linear Unit}) $f(x) =
\max(0,x)$, której wykres przedstawia rysunek \ref{fig:reLU}. Pozwala ona
uzyskać tą samą dokładność w czasie kilkukrotnie krótszym niż tradycyjnie
stosowane funkcje $f(x) = \tanh(x)$ lub $f(x) = (1 + e^{-x})^{-1}$. Ta sama
funkcja stosowana jest także na wyjściach warstw podpróbkujących.

\begin{figure}[!tbh]
  \centering
  \includegraphics[width=0.5\textwidth]{plots/relu.pgf}
  \caption{Funkcja aktywacji reLU}
  \label{fig:reLU}
\end{figure}

Wektory wag $\bm w_0,\dotsc,\bm w_m$ podlegają optymalizacji w procesie
uczenia, podobnie jak jądra w warstwach konwolucyjnych. Odbywa się to poprzez
wykonanie warstw sieci na danych treningowych i zastosowanie jednego z
algorytmów optymalizacyjnych, który, na podstawie tzw.\ funkcji strat modyfikuje wagi.
Kolejne iteracje tego procesu prowadzą do coraz dokładniejszych wyników
uzyskiwanych z sieci.

Dodatkowym typem warstw stosowanym w tego typu sieciach są warstwy typu
\textit{dropout} --- wyłączające. Posiadają one parametr $p$ który określa
prawdopodobieństwo z jakim każdy z elementów tensora zostanie przez warstwę
wyzerowany. Po przejściu przez tę warstwę tensor posiada około
$p\cdot\SI{100}{\percent}$ elementów wyzerowanych. Ta operacja pozwala zapobiec
sytuacji zwanej naddopasowaniem (eng.\textit{overfitting}), gdzie sieć
zapamiętuje obrazy treningowe, przez co uzyskuje niską dokładność dla obrazów jej
nieznanych.

\subsection{Konstrukcja modelu}
Model oparto na {\color{red}odnośnik}. Składa się z trzech warstw
konwolucyjnych o rozmiarze jądra $3 \times 3$ ze skokiem 1 i padem 0, przy czym
pierwsza posiada $1 \times 16$ takich jąder, a kolejne $16\times 16$. Po każdej
następuje warstwa podpróbkująca typu \textit{Max Pooling} o rozmiarze okna $2
\times 2$ ze skokiem $2$. Po tych warstwach następują dwie warstwy ukryte w
pełni połączone o trzystu węzłach i finalna warstwa w pełni połączona o liczbie
węzłów równej liczbie rozpoznawanych kategorii.  Ponadto warstwy w pełni
połączone korzystają z wyłączania (dropout), pierwsza z prawdopodobieństwem $p
= 0.3$, a dwie kolejne z prawdopodobieństwem $p = 0.2$.  Wszystkie warstwy z
pominięciem ostatniej korzystają z funkcji aktywacji reLU.  Rys.
\ref{fig:cnn_scheme} przedstawia tę architekturę sieci.
\begin{figure}[!tbh]
  \centering
  \scriptsize\import{vecgraphics/}{cnn-scheme2.pdf_tex}
  \caption{Model sieci konwolucyjnej}
  \label{fig:cnn_scheme}
\end{figure}

Do treningu wykorzystano metodę optymalizacji ADAM {\color{red}odnośnik}, a
jako funkcję strat wykorzystano NLL (\textit{Negative Log Likelihood}) $L(y) =
-\log(y)$.
\subsection{Implementacja modelu}
Do stworzenia modelu wykorzystano bibliotekę \textit{Knet.jl} (\textit{Koç
University deep learning framework}) i jezyk \textit{Julia}.

Ta biblioteka nie posiada predefiniowanych warstw, należy je zdefiniować
jako struktury, które można wywołać na danych. Kod \ref{lst:Knet_model}
przedstawia proces konstrukcji modelu wykorzystanego w pracy. Wpierw tworzona
jest warstwa konwolucyjna, posiada ona pola: \lstinline|w| --- wagi,
\lstinline|b| --- bias (wektor dodawany do danych wejściowych, uczony podobnie
jak wagi), \lstinline|f| --- funkcję aktywacji i \lstinline|p| ---
prawdopodobieństwo warstwy \textit{dropout}. Wywołanie tej warstwy stosuje
\textit{dropout} na danych wejściowych, po czym liczy splot z kolekcją filtrów,
stosuje podpróbkowanie \textit{Max Pooling}, dodaje bias i finalnie stosuje
funkcję aktywacji. Parametry uczone inicjalizuje funkcja \lstinline|param()|,
której argumenty oznaczają wymiary tensora parametrów. Funkcja
\lstinline|param0()|, działa tak samo, lecz inicjalizuje parametry jako zera, a
nie jako wartości losowe.

Analogicznie zdefiniowana jest warstwa w pełni połączona jako wynik
zastosowania funkcji aktywacji na wyniku sumy iloczynu tensora wag z danymi
wejściowymi i biasu. Tutaj funkcja \lstinline|mat()| spłaszcza tensor wejściowy
do wektora.

Ostatnia zdefiniowana jest warstwa \lstinline|Chain|, która służy do łączenia
warstw w łańcuch całego modelu. Wykonanie jej na danych wykonuje po kolei każdy
element łańcucha przekazując wynik z poprzedniego do następnego. Posiada też
możliwość wykonania na danych wejściowych i pożądanych wynikach, w takim
wypadku wyznacza funkcję strat NLL.

\begin{program}
  \caption{Konstrukcja modelu przy użyciu \textit{Knet.jl}}
  \label{lst:Knet_model}
  \begin{lstlisting}
  using Knet
  using Knet: Data

  struct Conv; w; b; f; p; end
  (c::Conv)(x) = c.f.(pool(conv4(c.w, dropout(x,c.p)) .+ c.b))
  Conv(w1::Int,w2::Int,cx::Int,cy::Int,f=relu;pdrop=0) = Conv(param(w1,w2,cx,cy), param0(1,1,cy,1), f, pdrop)

  struct Dense; w; b; f; p; end
  (d::Dense)(x) = d.f.(d.w * mat(dropout(x,d.p)) .+ d.b)
  Dense(i::Int,o::Int,f=relu;pdrop=0) = Dense(param(o,i), param0(o), f, pdrop)

  struct Chain; layers; Chain(layers...) = new(layers); end
  (c::Chain)(x) = (for l in c.layers; x = l(x); end; x)
  (c::Chain)(x,y) = nll(c(x),y)
  (c::Chain)(d::Data) = mean(c(x,y) for (x,y) in d)

  model = Chain(Conv(3, 3, 1, 16),
                Conv(3, 3, 16, 16),
                Conv(3, 3, 16, 16),
                Dense(102240, 300, pdrop=0.3),
                Dense(300, 300, pdrop=0.2),
                Dense(300, no_categories, identity, pdrop=0.2))
  \end{lstlisting}
\end{program}
\chapter{Ewaluacja}
\section{Dane ewaluacyjne}
Stworzono bazę danych fragmentów muzyki z prywatnych plików audio po
części kupionych na serwisach internetowych oferujących muzykę w formacie
bezstratnym, takich jak Bandcamp, a po części własnoręcznie zgranych z płyt
CD. Stworzono skrypt w jeżyku Python, korzystający z biblioteki pydub, który
z każdego ze znalezionych w folderze plików w formacie FLAC wybiera losowy
fragment o długości \SI{10}{\second}, po czym konwertuje go na każdy z listy
formatów, o każdym z listy stopni kompresji, i następnie z powrotem konwertuje
na sygnał nieskompresowany. Każdy z fragmentów jest normalizowana przed
kompresją oraz skwantyzowana do szesnastu bitów jeśli plik ma ich więcej. Pliki
i częstotliwości próbkowania różnej od $f_s = \SI{44100}{\hertz}$ są pomijana
by nie wprowadzać dodatkowej zmiennej w postaci artefaktów podpróbkowywania. W
przypadku uzyskania po konwersji pliku o większej ilości bitów niż szesnaście,
jest on ponownie rekwantyzowany do szesnastu (tak jest w przypadku AC-3 i WMA).
Wszystkie fragmenty w postaci ciągu próbek o długości $441000$ są zapisywane w
pliku HDF5 wraz z wartością liczbową określająca rodzaj i stopień kompresji.

Stopień kompresji regulowano za pomocą parametru \textit{bitrate} który oznacza
pożądaną po kompresji ilość bitów (oznaczającą rozmiar pliku na dysku) na
sekundę sygnału.

Wynikowa baza danych posiada 65536 fragmentów, 4096 w postaci
nieskompresowanej i po 4096 dla każdej z piętnastu możliwych par formatów MP3,
AAC, AC-3, Vorbis i WMA z bitrate'ami \SI{320}{\kibi\bit\per\second},
\SI{192}{\kibi\bit\per\second} i \SI{128}{\kibi\bit\per\second}.

\section{Oznaczenia}

W tablicach i na wykresach w tym rozdziale fragmenty niepoddane żadnej kompresji,
oznaczono skrótowo jak ,,WAV'', co nie oznacza oczywiście że te fragmenty były w tym
formacie oryginalnie ani że są one w tym formacie w bazie danych. W istocie są
one tak samo jak wszystkie inne fragmenty reprezentacją sygnału dźwiękowego w
postaci PCM. Zdecydowano się na takie oznaczenie by było analogiczne do
oznaczeń formatów skompresowanych z których wywodzi się dana próbka, a
format WAV jest kojarzony z plikami nieskompresowanymi. Warto zauważyć że jako
że sygnał ten nie został poddany żadnej kompresji stratnej oznaczenie go jako
jako ,,FLAC'' lub inny format bezstratny było by równoznaczne z ,,WAV'', gdyż
kompresja do tego formatu i z powrotem odtworzyła by dokładnie ten sam sygnał.

Jednostką birate'a wykorzystywanego w oznaczeniach tablic i wykresów są
\si{\kibi\bit\per\second}. Dokładność, podawana w \si{\percent} oznacza część
odpowiedzi dla których indeks maksimum wektora danych uzyskanych z sieci
pokrywał się z wartością liczbową oznaczającą kategorię badanego pliku. Inaczej
mówiąc jest to średnia ilość poprawnych odpowiedzi sieci na sto pytań.


\section{Identyfikacja algorytmiczna}
Ewaluację algorytmu przeprowadzono na 2048 dziesięciosekundowych próbkach audio
z bazy danych ewaluacyjnych. Na każdej z próbek przeprowadzono detekcję dla
każdego z pięciu zestawów parametrów kodeków. Jako transformację dla każdego z
kodeków wykorzystano MDCT, a skok wyznaczono jako połowę długości okna. Okna
wybrano: kosinusowe o długości 1152 próbek dla MP3, KBD z parametrem $\alpha =
4$ o długości 2048 dla AAC, zboczowe o długość 2048 dla Vorbis, KBD z
parametrem $\alpha = 5$ o długości 512 dla AC-3 i kosinusowe o długości 4096
dla WMA. Nie zastosowano normalizacji wektora $\bm d_i$. Każdą próbkę o
długości $S = \SI{10}{\second}$ podzielono na $m = 15$ fragmentów o długości
$L$, gdzie dla każdego zestawu parametrów $T(x),w(n),N,h$ wyznaczono ją jako:
\begin{equation}
  L = \left\lfloor\frac{S-h}{mN}\right\rfloor N
\end{equation}


Tablica \ref{tab:algo_eval} przedstawia wyniki średniej wartości parametru
$C_{T(x),w(n),N,h}$ oraz jego odchylenia standardowego dla detekcji każdym
zestawem parametrów na każdym z typów pliku.

\begin{table}[!tbh]
  \sisetup{round-precision=2, round-mode=places}
  \centering
  \caption{Wartości parametru $C_{T(x),w(n),N,h}$}
  \include{tables/algo_eval}
  \label{tab:algo_eval}
\end{table}

Pierwsza rzecz na którą warto zwrócić uwagę to niskie wartości średniej
parametru rzędu \num{0.005} w przypadku zastosowaniu algorytmu na sygnale
niepoddanym kompresji (oznaczonym ,,WAV'' w tablicy), to i odchylenie standardowe
na poziome \num{0.001} wskazuje że algorytm nie posiada problemu z
identyfikacją pliku nieskompresowanego jako skompresowany, oraz jednocześnie
wskazuje na bardzo małą (lub żadną) zawartość plików mylnie uznanych za
nieskompresowane w bazie danych. 

Algorytm zwraca wartości kilka do stukilkudziesięciu razy większe zastosowany na pliku o
parametrach zgodnych z zastosowanymi niż dla pliku nieskopmresowanego, w
szczególności największe wartości zwraca detekcja WMA dla pliku WMA osiągając
średnio \num{0.63} dla bitrate'a \SI{128}{\kibi\bit\per\second} (około 120
razy więcej niż dla pliku nieskompresowanego). Natomiast
najmniejsze wartości występują dla MP3 i AC-3 które zwracają średnio \num{0.02}
dla bitrate'a \SI{320}{\kibi\bit\per\second} (około 7 razy więcej nż dla pliku
nieskompresowanego). Oznacza to, że ustalenie odpowiednich wartości granicznych
pozwoli rozpoznać czy kompresję na pliku z dużą dokładnością.

Rozpoznanie który rodzaj kompresji może być niedokładne z powodu występowania
dużych wartości parametru w pewnych przypadkach detekcji pliku innego typu niż
tego którego parametry wykorzystano do identyfikacji. Ten problem występuje dla
każdego typu plików, lecz najmniejszy jest w przypadku detekcji parametrami
AC-3, w tym przypadku największe wartości jakie średnio uzyskują inne pliki nie
przekraczają \num{0.01}. Jednak występowanie tego problemu oznacza że aby nie
tylko rozpoznać czy kompresja została zastosowana ale też rozpoznać jaki kodek
był zastosowany do tej kompresji należy wykonać algorytm dla każdego znanego
zestawu parametrów i następnie porównując wartości znaleźć najbardziej
prawdopodobny typ kompresji. To podejście jednak też może zawieść, szczególnie
w przypadku plików AC-3, gdzie identyfikacja z parametrami kodeku WMA uzyskuje
średnio większe wartości dla bitrate'ów \SI{320}{\kibi\bit\per\second} i
\SI{192}{\kibi\bit\per\second} oraz w przypadku plików Vorbis, gdzie detekcja z
parametrami kodeku AAC uzyskuje średnio większe wartości dla bitrate'a
\SI{320}{\kibi\bit\per\second}.
\section{Identyfikacja modelem}
Model wytrenowano w trzech konfiguracjach, w każdej jego architektura była taka
sama, za wyjątkiem liczby parametrów wyjściowych ostatniej warstwy
odpowiadającej liczbie rozpoznawanych kategorii. Model trenowano na danych z
bazy danych ewaluacyjnych wybieranych w ten sposób by ich liczba dla każdej
kategorii była zbliżona oraz by każdy format kompresji występował z podobną
częstotliwością. Dane audio zostały poddane transformacji STFT z oknem Hanninga
o długości 512 próbek i skokiem 256 próbek.

Trening prowadzono przez dziesięć epok zapisując model który uzyskał największą
dokładność na danych treningowych.

\subsection{Identyfikacja kompresji}
\begin{figure}[!tbh]
  \centering
  \includegraphics[width=0.9\textwidth]{plots/model_c.pgf}
  \caption{Nauka modelu rozpoznającego kompresję}
  \label{fig:model_c}
\end{figure}
Pierwszy trening wykonano dla dwóch kategorii: plików poddanych uprzedniej
kompresji i plików jej niepoddanym. Trening przeprowadzono na 5120 próbkach, a
testowano na 2560 próbkach. Sieć w tej postaci największą dokładność na danych
testowych, wynoszącą \SI{97.4}{\percent}, uzyskała po ośmiu epokach.

\begin{table}[!tbh]
  \sisetup{round-precision=1, round-mode=places}
  \centering
  \caption{Macierz konfuzji modelu rozpoznającego kompresję}
  \include{tables/model_c}
  \label{tab:model_c}
\end{table}

Rysunek \ref{fig:model_c} przedstawia dokładność testową uzyskaną dla każdego
rodzaju próbki przez osiem epok treningu. Natomiast tablica \ref{tab:model_c}
przedstawia tę dokładność w postaci macierzy dla finalnego modelu. Jak łatwo
zauważyć największym wyzwaniem dla sieci było oznaczenie plików skompresowanych
kodekiem MP3. Dla bitrate'a \SI{320}{\kibi\bit\per\second} dopiero po trzech
epokach uzyskano dokładność powyżej \SI{80}{\percent}, a finalna sieć
rozpoznaje poprawie pliki MP3 o tym bitrate dla \SI{88.4}{\percent} przypadków.
Rozpoznawalność MP3 była również niska dla pozostałych bitrate'ów osiagając
odpowiednio \SI{93}{\percent} i \SI{96.5}{\percent} dla
\SI{192}{\kibi\bit\per\second} i \SI{128}{\kibi\bit\per\second}, co jest
najgorszymi wynikami dla tych bitrate'ów. Natomiast dla bitrate'a
\SI{320}{\kibi\bit\per\second} najgorsze wyniki osiągnął format WMA, gdzie
dokładnośc rozpoznawania wynosiła \SI{87.1}{\percent}. Niskie dokładności dla
tych formatów wskazują na podobieństwo do sygnału źródłowego lub występowanie
cech o innym charakterze niż dla pozostałych kodeków.

Najlepsze dokładności uzyskały Vorbis i AC-3 z średnią dokładnością
\SI{99.6}{\percent} przy czym, co interesujące, AC-3, jako jedyny kodek uzyskał
najgorsze wyniki dla najmniejszego bitrate'a, natomiast jest to najpewniej
kwestia przypadku.
\subsection{Identyfikacja typu kompresji}
Liczba kategorii w przypadku identyfikacji typu kompresji wynosiła sześć, model
rozpoznawał z jakiego formatu został uzyskany fragment. Trening przeprowadzono
na 5120 fragmentach, a testowano na 2560 fragmentach. W tym przypadku
największą dokładność na danych testowych, wynoszącą \SI{96.1}{\percent},
uzyskano po trzech epokach.

\begin{figure}[!tbh]
  \centering
  \includegraphics[width=0.9\textwidth]{plots/model_c_t.pgf}
  \caption{Nauka modelu rozpoznającego typ kompresji}
  \label{fig:model_c_t}
\end{figure}

Jak przedstawiają rysunek \ref{fig:model_c_t} i tablica \ref{tab:model_c_t},
format MP3 również w tym przypadku stanowił problem dla modelu. W szczególności
można zauważyć, że pliki nieskompresowane są w \SI{4.9}{\percent} przypadków
rozpoznawane jako MP3, natomiast pliki MP3 są mylone z plikami
nieskompresowanymi w średnio \SI{4.4}{\percent} przypadków. Wskazuje to na
podobieństwo spektrogramu plików MP3 do spektrogramu pliku źródłowego,
utrudniające rozróżnienie. Ponadto dla bitrate'a \SI{320}{\kibi\bit\per\second}
MP3 jest mylone w \SI{4.9}{\percent} przypadków z formatem WMA, co również
sugeruje podobieństwo tych fragmentów do plików źródłowych, co zdaje się
potwierdzać mylność rozpoznawania tego formatu z plikiem nieskompresowanym na
poziomie \SI{2.1}{\percent}.

Można także zaważyć występowanie podobieństw pomiędzy plikami skompresowanymi
kodekiem Vorbis i AAC, na co wskazuje mylność AAC z Vorbis wynosząca średnio
\SI{4.4}{\percent} i mylność Vorbis z AAC na wynosząca średnio
\SI{1.6}{\percent}.
\begin{table}[!tbh]
  \sisetup{round-precision=1, round-mode=places}
  \centering
  \caption{Macierz konfuzji modelu rozpoznającego typ kompresji}
  \include{tables/model_c_t}
  \label{tab:model_c_t}
\end{table}
\subsection{Identyfikacja typu i parametrów kompresji}
Jako ostatni wytrenowano model wykorzystując wszystkie dostępne kategorie,
otrzymując ich szesnaście. Model trenowano na 8192 fragmentach, a testowano na
4096 fragmentach. Największą dokładność na danych testowych, wynoszącą
\SI{92.4}{\percent} uzyskano po siedmiu epokach.

Jak można zobaczyć na rysunku \ref{fig:model_c_t+p} oraz w tablicy
\ref{tab:model_c_t+p}, w przypadku tego modelu najgorsze wyniki uzyskują
fragmenty skompresowane przez kodek Vorbis co wynika z dużej mylności modelu w
rozróżnianiu pomiędzy bitrate'ami tego kodeka. Bitrate
\SI{320}{\kibi\bit\per\second} mylony jest w \SI{10.2}{\percent} przypadków z
bitratem \SI{192}{\kibi\bit\per\second} i w \SI{2}{\percent} przypadków z
bitratem \SI{128}{\kibi\bit\per\second}, bitrate \SI{192}{\kibi\bit\per\second}
mylony jest w \SI{5.5}{\percent} przypadków z bitratem
\SI{320}{\kibi\bit\per\second} i aż w \SI{23}{|percent} przypadków z bitratem
\SI{128}{\kibi\bit\per\second}, a bitrate \SI{128}{\kibi\bit\per\second} mylony
jest z bitratem \SI{192}{\kibi\bit\per\second} w \SI{14.1}{\percent}
przypadków. W efekcie powoduje to średnią dokładność dla tego kodeka
wynoszącą \SI{78.3}{\percent}.

Ponadto podobnie jak w poprzednich modela występuje mylność MP3 z formatem
nieskompresowanym wynosząca średnio \SI{5.5}{\percent}. Także też występuje
mylność formatu AAC z Vorbis, w szczególności dla bitrate'a
\SI{128}{\kibi\bit\per\second}, który mylony jest odpowiednio w \SI{9.4}{\percent},
\SI{2}{\percent} i \SI{1.2}{\percent} z Vorbis o bitrate
\SI{320}{\kibi\bit\per\second}, \SI{196}{\kibi\bit\per\second} i
\SI{128}{\kibi\bit\per\second}.

Najprecyzyjniej wykrywane są pliki AC-3 z dokładnością \SI{99.2}{\percent} dla
bitrate'a \SI{320}{\kibi\bit\per\second}, \SI{100}{\percent} dla
\SI{192}{\kibi\bit\per\second} i \SI{98.8}{\percent} dla
\SI{128}{\kibi\bit\per\second}.

\begin{figure}[!tbh]
  \centering
  \includegraphics[width=0.9\textwidth]{plots/model_c_t+p.pgf}
  \caption{Nauka modelu rozpoznającego typ i parametry kompresji}
  \label{fig:model_c_t+p}
\end{figure}
\begin{sidewaystable}[!tbh]
  \sisetup{round-precision=1, round-mode=places}
  \centering
  \caption{Macierz konfuzji modelu rozpoznającego typ i parametry kompresji}
  \include{tables/model_c_t+p}
  \label{tab:model_c_t+p}
\end{sidewaystable}

\chapter{Podsumowanie}
\section{Wnioski końcowe}
W pracy przedstawiono dwa zaimplementowane rozwiązania pozwalające
przeprowadzić analizę na fragmencie sygnału audio, w której wyniku możliwe jest
stwierdzenie czy dany sygnał został uprzednio poddany kompresji stratnej oraz
jaki był kodek zastosowany, a nawet jaki był poziom zastosowanej kompresji
(bitrate).

Podejście oparte o techniki uczenia maszynowego okazało się być znacznie lepsze
zwracając dużo precyzyjniejsze wyniki, co w dużej mierze jest spowodowane
uproszczonym modelem kompresji stratnej zakładanej przez algorytm oraz
niezmiennością jego parametrów takich jak długość czy rodzaj okna, mimo że
enkoder je zmienia. Ponadto duża złożoność algorytmu, mimo wprowadzonych
optymalizacji, powoduje długi czas przetwarzania, w przeciwieństwie do prostych
przekształceń opartych o mnożenie macierzowe wymaganych przez model. Zaletą
podejścia algorytmicznego jest brak potrzeby posiadania danych treningowych co
pozwala wykryć kompresję w takim przypadku, może być to użyte, gdy niepewna
jest jakość danych treningowych, by odrzucić fragmenty podejrzane o uzyskane
z plików skompresowanych i w efekcie poprawić dokładność modelu.

Zaprojektowana architektura modelu uzyskuje na tyle dużą dokładność że może być
użyta przez serwisy sprzedające muzykę w formatach bezstratnych do wykrycia
plików, nie będących w rzeczywistości bezstratnymi, lecz uzyskanych poprzez
dekompresję z formatu stratnego. Tego typu serwisy mają dostęp do dużej bazy
fragmentów na których model może być wytrenowany, ponadto w celu wstępnej
filtracji może być zastosowany opisany w pracy algorytm. Ten sam proces może
też być zastosowany przez użytkownika tych serwisów.

\section{Dalsze kierunki badań}

W dalszych pracach można poprowadzić kolejną optymalizację algorytmu oraz
dodanie innych kodeków do biblioteki \textit{IOLA.jl}, jak również
przeprowadzenie badań na wyznaczeniem odpowiednich wartości granicznych
parametrów uzyskanych z algorytmu by uzyskać jak najlepszą detekcję.

Usprawnienie modelu można przeprowadzić poprzez zwiększenie jego złożoności,
przez zwiększenie długość warstw w pełni połączonych, wydłużenie treningu i
podanie większej ilości danych. Ponadto można wprowadzić więcej kodeków do bazy
danych, żeby zwiększyć wszechstronność modelu. Aby zobaczyć jak model
rozpoznaje nieznane formy kompresji można wytrenować go na danych z wyłączeniem
pewnych kodeków i zaobserwować wyniki dla tych kodeków podczas treningu.


%Kod poniżej dodaje Bibliografię do spisu treści
\cleardoublepage{}
\phantomsection{}
\addcontentsline{toc}{chapter}{Bibliografia}
\printbibliography{}

\end{document}
